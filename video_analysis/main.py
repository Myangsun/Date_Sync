import os
import argparse
import numpy as np

from utils.video_io import extract_audio_and_frames
from utils.visualization import create_metrics_visualization
from analysis.text_features import extract_text_features
from analysis.audio_features import extract_audio_features
from analysis.visual_features import extract_visual_time_series
from analysis.face_mesh import extract_face_mesh_time_series
from analysis.crossmodal_analysis import analyze_multimodal_features


def analyze_video(video_path, output_root):
    # è·å–è§†é¢‘æ–‡ä»¶åï¼Œä¸å¸¦æ‰©å±•å
    video_name = os.path.splitext(os.path.basename(video_path))[0]
    output_dir = os.path.join(output_root, video_name)
    os.makedirs(output_dir, exist_ok=True)

    # è®¾å®šè¾“å‡ºè·¯å¾„
    audio_path = os.path.join(output_dir, "audio.wav")
    frames_dir = os.path.join(output_dir, "frames")

    # 1. æŠ½å¸§ & éŸ³é¢‘
    total_frames, fps, duration = extract_audio_and_frames(video_path, audio_path, frames_dir)
    print(f"\nğŸï¸ [{video_name}] {total_frames}å¸§ @ {fps:.2f}fps, æ—¶é•¿ {duration:.1f}s")

    # 2. Whisper æ–‡æœ¬æƒ…ç»ª
    text, text_feat = extract_text_features(audio_path)

    # 3. å£°éŸ³ç‰¹å¾ï¼ˆpitch, intensityï¼‰
    audio_feat = extract_audio_features(audio_path)

    # 4. å›¾åƒæƒ…ç»ª valenceï¼ˆFERï¼‰
    valence, emotion_data = extract_visual_time_series(frames_dir)

    # 5. é¢éƒ¨ç‰¹å¾ï¼ˆmediapipeï¼‰
    saccade, comfort, face_features = extract_face_mesh_time_series(frames_dir)

    # 6. å¯è§†åŒ–è¾“å‡ºï¼ˆå›¾ + CSVï¼‰
    metrics_png, metrics_csv = create_metrics_visualization(
        fps, valence, emotion_data, face_features, output_dir
    )

    # 7. GPT è·¨æ¨¡æ€æ€»ç»“
    analysis = analyze_multimodal_features(
        text, text_feat, audio_feat, valence, saccade, comfort
    )
    with open(os.path.join(output_dir, "crossmodal_analysis.txt"), "w") as f:
        f.write(analysis)

    print(f"\nâœ… å®Œæˆ â†’ {output_dir}")
    return output_dir


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Run multimodal emotion analysis on video(s)")
    parser.add_argument("video_paths", nargs="+", help="Path(s) to video file(s)")
    parser.add_argument("--output-dir", default="output", help="Root directory for output")
    args = parser.parse_args()

    for video_path in args.video_paths:
        analyze_video(video_path, args.output_dir)
